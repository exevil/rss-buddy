name: Process RSS Feeds

on:
  schedule:
    - cron: '0 */12 * * *'  # Run every 12 hours
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [ main ]
    paths:
      - '**.py'
      - '.github/workflows/process-rss.yml'
      - 'rss-buddy.sh'

jobs:
  process-rss:
    runs-on: ubuntu-latest
    # Use the github-pages environment where all secrets are stored
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
      - name: Checkout main branch
        uses: actions/checkout@v4
        with:
          ref: main
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install feedparser python-dateutil openai python-dotenv requests
      
      # Download state file from GitHub Pages if it exists
      - name: Fetch latest state from GitHub Pages
        id: fetch_state
        run: |
          mkdir -p processed_feeds
          # For user pages format: username.github.io/repo
          # For org pages format: org.github.io/repo
          REPO_NAME=$(echo ${{ github.repository }} | cut -d '/' -f 2)
          PAGES_URL="${{ github.repository_owner }}.github.io/$REPO_NAME"
          STATE_URL="https://${PAGES_URL}/processed_state.json"
          
          echo "Attempting to download state from $STATE_URL"
          
          # Try to download the state file
          HTTP_CODE=$(curl -s -o processed_feeds/processed_state.json -w "%{http_code}" "$STATE_URL")
          
          if [ "$HTTP_CODE" -eq 200 ]; then
            echo "State file successfully downloaded"
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "No state file found at $STATE_URL (HTTP code: $HTTP_CODE)"
            echo "found=false" >> $GITHUB_OUTPUT
            # Remove the potentially incomplete download
            rm -f processed_feeds/processed_state.json
          fi
          
      # Use secrets from the github-pages environment
      - name: Process RSS feeds
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          RSS_FEEDS: ${{ vars.RSS_FEEDS }}
          USER_PREFERENCE_CRITERIA: ${{ vars.USER_PREFERENCE_CRITERIA }}
          DAYS_LOOKBACK: ${{ vars.DAYS_LOOKBACK || secrets.DAYS_LOOKBACK }}
          AI_MODEL: ${{ vars.AI_MODEL || secrets.AI_MODEL }}
          SUMMARY_MAX_TOKENS: ${{ vars.SUMMARY_MAX_TOKENS || secrets.SUMMARY_MAX_TOKENS }}
        run: |
          python rss_processor.py
          
      - name: Generate GitHub Pages
        run: |
          # The generate_pages.py script already copies all XML files and the state file to the docs directory
          python generate_pages.py
      
      # Configure Pages
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      # Upload artifact for GitHub Pages
      - name: Upload pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'docs'
      
      # Deploy to GitHub Pages
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4 
